{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27a2ccb92b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.mod\n",
    "inputs = Input((28, 28, 1))\n",
    "\n",
    "net = Conv2D(32, (3, 3), padding='same')(inputs) \n",
    "net = Activation('relu')(net)\n",
    "net = Conv2D(32, (3, 3), padding='same')(inputs) \n",
    "net = Activation('relu')(net)\n",
    "net = MaxPooling2D(pool_size=(2, 2))(net) \n",
    "net = Dropout(0.25)(net)\n",
    "\n",
    "net = Conv2D(128, (3, 3), padding='same')(net) \n",
    "net = Activation('relu')(net)\n",
    "net = Conv2D(128, (3, 3), padding='same')(net) \n",
    "net = Activation('relu')(net)\n",
    "net = MaxPooling2D(pool_size=(2, 2))(net) \n",
    "net = Dropout(0.25)(net)\n",
    "\n",
    "net = Flatten()(net) \n",
    "net = Dense(512)(net) \n",
    "net = Activation('relu')(net) \n",
    "net = Dropout(0.25)(net)\n",
    "net = Dense(10)(net) \n",
    "net = Activation('softmax')(net) \n",
    "\n",
    "model = Model(inputs=inputs, outputs=net)\n",
    "\n",
    "# net = Conv2D(128, (3, 3), padding='same')(net) \n",
    "# net = Activation('relu')(net)\n",
    "# net = Conv2D(128, (3, 3), padding='same')(net) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,401,802\n",
      "Trainable params: 3,401,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr)\n",
    "            , loss='sparse_categorical_crossentropy'\n",
    "            , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 152s 34ms/step - loss: 1.6742 - accuracy: 0.7542 - val_loss: 0.4842 - val_accuracy: 0.8416\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 158s 35ms/step - loss: 0.7848 - accuracy: 0.7476 - val_loss: 0.5188 - val_accuracy: 0.8195\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 146s 33ms/step - loss: 0.7158 - accuracy: 0.7668 - val_loss: 0.5343 - val_accuracy: 0.8293\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 149s 33ms/step - loss: 0.7353 - accuracy: 0.7590 - val_loss: 0.5063 - val_accuracy: 0.8351\n",
      "Epoch 5/10\n",
      "1613/4500 [=========>....................] - ETA: 1:36 - loss: 0.7017 - accuracy: 0.7696"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEHWAN~1\\AppData\\Local\\Temp/ipykernel_25472/3049082570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.25, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evalute(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(1000).batch(32) \n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.batch(32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_object(): \n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function \n",
    "def train_step(images, label): \n",
    "    with tf.GradientTape() as tape: \n",
    "        prediction = model(images)\n",
    "        loss = loss_object(label, prediction) \n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function \n",
    "def test_step(images, label): \n",
    "    with tf.GradientTape() as tape: \n",
    "        prediction = model(images)\n",
    "        t_loss = loss_object(label, prediction) \n",
    "    # gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.appy_gradient(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    test_loss(t_loss) \n",
    "    test_accuracy(label, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 2.3007915019989014, accuracy : 11.78833293914795, test_loss : 2.298938512802124, test_accuracy : 13.699999809265137\n",
      "epoch : 2, loss : 2.0655930042266846, accuracy : 22.199167251586914, test_loss : 1.555168628692627, test_accuracy : 43.30999755859375\n",
      "epoch : 3, loss : 1.6213829517364502, accuracy : 39.823890686035156, test_loss : 1.2673311233520508, test_accuracy : 54.45000076293945\n",
      "epoch : 4, loss : 1.3771734237670898, accuracy : 49.37458419799805, test_loss : 1.1090033054351807, test_accuracy : 60.49500274658203\n",
      "epoch : 5, loss : 1.219873070716858, accuracy : 55.492000579833984, test_loss : 1.0120010375976562, test_accuracy : 64.11199951171875\n",
      "epoch : 6, loss : 1.1092227697372437, accuracy : 59.7400016784668, test_loss : 0.9393016695976257, test_accuracy : 66.88999938964844\n",
      "epoch : 7, loss : 1.0265611410140991, accuracy : 62.89047622680664, test_loss : 0.8856035470962524, test_accuracy : 68.894287109375\n",
      "epoch : 8, loss : 0.9620386958122253, accuracy : 65.33000183105469, test_loss : 0.8448168635368347, test_accuracy : 70.3762435913086\n",
      "epoch : 9, loss : 0.9109858274459839, accuracy : 67.27352142333984, test_loss : 0.8111729621887207, test_accuracy : 71.63333129882812\n",
      "epoch : 10, loss : 0.868161678314209, accuracy : 68.8844985961914, test_loss : 0.7830013632774353, test_accuracy : 72.68699645996094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): \n",
    "\n",
    "    for images, label in train_ds: \n",
    "        train_step(images, label) \n",
    "\n",
    "    for images, label in test_ds: \n",
    "        test_step(images, label) \n",
    "\n",
    "    temp = 'epoch : {}, loss : {}, accuracy : {}, test_loss : {}, test_accuracy : {}'\n",
    "    print(temp.format(epoch+1\n",
    "                    , train_loss.result() \n",
    "                    , train_accuracy.result() * 100 \n",
    "                    , test_loss.result() \n",
    "                    , test_accuracy.result() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "mobilenetv2 = MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv2.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv2.layers[:-1]:\n",
    "    if 'kernel' in layer.__dict__: \n",
    "        kernel_shape = np.array(layer.get_weights()).shape\n",
    "\n",
    "        layer.set_weights(tf.random.normal(kernel_shape, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x296f4b0a7c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297340bbfa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297340ea910>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297340ea6a0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x29734178d90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a5079d0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a4f1910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a51b070>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a52d400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a6c20a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a507940>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a6c26a0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x2973a6ce730>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973a6ce1f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a5268e0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29734178ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a4f1ca0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a6d5790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a6ca700>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a526790>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a6c2c10>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973a6e18e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a6e79d0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a6e73a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a6f07c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a6f2790>,\n",
       " <keras.layers.merge.Add at 0x2973a6f2970>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a6f8340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a6fb7f0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a6fbcd0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x2973a814430>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973a81aee0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a820f70>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a820dc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a51b9d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a827df0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a827520>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a830f40>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a8321f0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973a8322e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a8406a0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a843640>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a843b20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a84ea30>,\n",
       " <keras.layers.merge.Add at 0x2973b972790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b972fa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b978fa0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973b985130>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973b985c40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b98a6d0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973b990670>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b990b50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b9785e0>,\n",
       " <keras.layers.merge.Add at 0x2973a832ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a8302b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a820f10>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a6c2220>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x2973a5269a0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973b972dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b995e50>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973b99af70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b99a850>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b99cd60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b99dac0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b99f100>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973b99d370>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2973b9a5bb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b9aac10>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973b9a5400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b9aff70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747765670>,\n",
       " <keras.layers.merge.Add at 0x29747765fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b9aa6d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747770ac0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747770e80>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x29747777a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747782790>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747782760>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b9af820>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2974778aa30>,\n",
       " <keras.layers.merge.Add at 0x2974778a220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x29747787c40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747798be0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747798580>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x29747787b20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477a3df0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477a3ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2974779ffd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477b5160>,\n",
       " <keras.layers.merge.Add at 0x297477b5130>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477b00d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477793a0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747770940>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2974779f160>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973b99af40>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2973a820130>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973b99d3d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2973a827730>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2973a827070>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477bdfa0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477bf1f0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x297477bf250>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477c5700>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477c66a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477c6b80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477cda90>,\n",
       " <keras.layers.merge.Add at 0x297477d47f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477d4f40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477e2130>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477e7190>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x297477e7d00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477eb760>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477f0700>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477f0be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477f8ac0>,\n",
       " <keras.layers.merge.Add at 0x297477ff850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477fffa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2974780b160>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747811040>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x29747811070>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x29747803730>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2974781e190>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477ffac0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2974780bf40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747825f70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x29747830100>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2974782af70>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2974782aeb0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2974780be80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477ff910>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x297477f8a30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x297477d4d90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297477bc790>,\n",
       " <keras.layers.merge.Add at 0x297477bc130>,\n",
       " <keras.layers.convolutional.Conv2D at 0x29747816280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747779fd0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747782c10>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x297477c15e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x2974783a4f0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2974783a4c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x29747838850>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x297478407c0>,\n",
       " <keras.layers.merge.Add at 0x29747840160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2974783da30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747849970>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747849310>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x29747845ac0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747854be0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747854bb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2974784fd60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747860e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2974785bbe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x29747867fa0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x29747860670>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x297478623d0>,\n",
       " <keras.layers.core.Dense at 0x29747879370>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv2.layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = tf.convert_to_tensor(x_train[..., tf.newaxis])\n",
    "# test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(32, 32, 3), \n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.engine.input_layer.InputLayer object at 0x00000296F4B0A7C0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/2656484251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# inputs = mobilenetv2.input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmobilenetv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmobilenetv2_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m         training=training_mode):\n\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;31m# have a `shape` attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Inputs to a layer should be tensors. Got: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.engine.input_layer.InputLayer object at 0x00000296F4B0A7C0>"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input((28, 28, 3))\n",
    "# inputs = mobilenetv2.input\n",
    "net = mobilenetv2.layers[:-2]\n",
    "net = tf.keras.layers.Dense(10, activation='softmax')(net) \n",
    "\n",
    "mobilenetv2_model = tf.keras.Model(inputs=inputs, outputs=net)\n",
    "mobilenetv2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ad7f8df95050390ccef3c53b91cc5366ee05cbbc975f965dd0a4e5b2556ae66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
